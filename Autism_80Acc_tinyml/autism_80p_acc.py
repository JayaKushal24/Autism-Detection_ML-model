# -*- coding: utf-8 -*-
"""AUTISM_80p_Acc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wp4uglGlAZgNfeOuIm3cRgIw3LF3sbYi
"""

import tensorflow as tf
import numpy as np
import os
import matplotlib.pyplot as plt

IMG_SIZE = 64
CHANNELS = 1  

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

data_dir = '/content/drive/MyDrive/Autistic_cleandata'

def preprocess(img, label):
    img = tf.image.rgb_to_grayscale(img)
    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])
    img = tf.cast(img, tf.float32) / 255.0
    return img, label

data = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    image_size=(256, 256),  
    batch_size=32,
    label_mode='int'
)

data = data.map(preprocess).cache().shuffle(1000).prefetch(tf.data.AUTOTUNE)

train_size = int(0.75 * len(data))
val_size = int(0.15 * len(data))
test_size = int(0.1 * len(data))

train = data.take(train_size)
val = data.skip(train_size).take(val_size)
test = data.skip(train_size + val_size).take(test_size)

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input

model = Sequential([
    Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS)),
    Conv2D(8, (3,3), activation='relu'),
    MaxPooling2D(),
    Conv2D(16, (3,3), activation='relu'),
    MaxPooling2D(),
    Flatten(),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.summary()


from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.2)

history = model.fit(train, epochs=20, validation_data=val, callbacks=[early_stop, reduce_lr])


model.evaluate(test)

from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy


precision = Precision()
recall = Recall()
binary_accuracy = BinaryAccuracy()


for batch in test.as_numpy_iterator():
    X, y_true = batch
    y_pred = model.predict(X)

    precision.update_state(y_true, y_pred)
    recall.update_state(y_true, y_pred)
    binary_accuracy.update_state(y_true, y_pred)


print(f"Test Accuracy     : {binary_accuracy.result().numpy() * 100:.2f}%")
print(f"Test Precision    : {precision.result().numpy() * 100:.2f}%")
print(f"Test Recall       : {recall.result().numpy() * 100:.2f}%")

import cv2
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

IMG_SIZE = 64 

img_path = '/content/drive/MyDrive/AutismDataset/test/Autistic.112.jpg'
img = cv2.imread(img_path)

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title("Input Image")
plt.show()

resize = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))

plt.imshow(resize.numpy().astype(np.uint8))
plt.axis('off')
plt.title("Resized Image")
plt.show()

input_tensor = np.expand_dims(resize / 255.0, axis=0)
if input_tensor.shape[-1] != 1:
 
    input_tensor = tf.image.rgb_to_grayscale(input_tensor)

pred = model.predict(input_tensor)

print(f"Raw prediction: {pred[0][0]:.4f}")
if pred > 0.5:
    print("Predicted: Not Autistic")
else:
    print("Predicted: Autistic")

model.save('tiny_autism_model.h5')