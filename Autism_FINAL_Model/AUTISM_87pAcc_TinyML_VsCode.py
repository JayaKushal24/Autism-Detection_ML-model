# -*- coding: utf-8 -*-
"""AUTISM_87p_Acc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UXqn2N8mimcNWY3mCnxv9o9JUghP2Z3p
"""

import tensorflow as tf
import numpy as np
import os
import matplotlib.pyplot as plt

IMG_SIZE = 64
CHANNELS = 1  

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

data_dir = '/content/drive/MyDrive/Autistic_cleandata'

def preprocess(img, label):
    img = tf.image.rgb_to_grayscale(img)
    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])
    img = tf.cast(img, tf.float32) / 255.0
    return img, label

data = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    image_size=(256, 256),
    batch_size=32,
    label_mode='int'
)

data = data.map(preprocess).cache().shuffle(1000).prefetch(tf.data.AUTOTUNE)

train_size = int(0.75 * len(data))
val_size = int(0.15 * len(data))
test_size = int(0.1 * len(data))

train = data.take(train_size)
val = data.skip(train_size).take(val_size)
test = data.skip(train_size + val_size).take(test_size)

# from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input

# model = Sequential([
#     Input(shape=(IMG_SIZE, IMG_SIZE, CHANNELS)),
#     Conv2D(8, (3,3), activation='relu'),
#     MaxPooling2D(),
#     Conv2D(16, (3,3), activation='relu'),
#     MaxPooling2D(),
#     Flatten(),
#     Dense(16, activation='relu'),
#     Dense(1, activation='sigmoid')
# ])


from tensorflow.keras import layers

model = Sequential([
    layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS)), 
    Conv2D(8, (3, 3), activation='relu'),
    MaxPooling2D(),
    Conv2D(16, (3, 3), activation='relu'),
    MaxPooling2D(),
    Flatten(),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')
])


model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.summary()


from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.2)

history = model.fit(train, epochs=20, validation_data=val, callbacks=[early_stop, reduce_lr])


model.evaluate(test)

from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy


precision = Precision()
recall = Recall()
binary_accuracy = BinaryAccuracy()


for batch in test.as_numpy_iterator():
    X, y_true = batch
    y_pred = model.predict(X)

    precision.update_state(y_true, y_pred)
    recall.update_state(y_true, y_pred)
    binary_accuracy.update_state(y_true, y_pred)

print(f"Test Accuracy     : {binary_accuracy.result().numpy() * 100:.2f}%")
print(f"Test Precision    : {precision.result().numpy() * 100:.2f}%")
print(f"Test Recall       : {recall.result().numpy() * 100:.2f}%")

import cv2
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

IMG_SIZE = 64  

img_path = '/content/drive/MyDrive/AutismDataset/test/Autistic.112.jpg'
img = cv2.imread(img_path)

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title("Input Image")
plt.show()

resize = tf.image.resize(img, (IMG_SIZE, IMG_SIZE)) 

plt.imshow(resize.numpy().astype(np.uint8))
plt.axis('off')
plt.title("Resized Image")
plt.show()

input_tensor = np.expand_dims(resize / 255.0, axis=0) 
if input_tensor.shape[-1] != 1:
    input_tensor = tf.image.rgb_to_grayscale(input_tensor)

pred = model.predict(input_tensor)


print(f"Raw prediction: {pred[0][0]:.4f}")
if pred > 0.5:
    print("Predicted: Not Autistic")
else:
    print("Predicted: Autistic")

# import cv2
# import matplotlib.pyplot as plt
# import numpy as np
# import tensorflow as tf

# IMG_SIZE = 64  # your model input size

# # === 1. Load, resize, and normalize image ===
# img_path = '/content/drive/MyDrive/AutismDataset/test/Autistic.112.jpg'
# img = cv2.imread(img_path)

# # Resize and normalize in one step
# img_resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0  # Normalize the image while resizing

# # Convert to uint8 before color conversion
# img_resized = (img_resized * 255).astype(np.uint8)

# # === 2. Convert to grayscale if needed ===
# img_resized = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)  # If the model expects grayscale images

# # === 3. Expand dimensions to match input shape ===
# input_tensor = np.expand_dims(img_resized, axis=0)  # shape: (1, IMG_SIZE, IMG_SIZE, 1) for grayscale

# # === 4. Predict ===
# pred = model.predict(input_tensor)

# # === 5. Output prediction ===
# print(f"Raw prediction: {pred[0][0]:.4f}")
# if pred > 0.5:
#     print("Predicted: Not Autistic")
# else:
#     print("Predicted: Autistic")

model.save('tiny_autism_model2.h5')

import cv2
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf


from google.colab import drive
drive.mount('/content/drive', force_remount=True)

model_path = '/content/drive/MyDrive/tiny_autism_model2.h5'
img_path = '/content/drive/MyDrive/AutismDataset/test/Autistic.112.jpg'


model = tf.keras.models.load_model(model_path)
print("âœ… Model loaded.")


IMG_SIZE = 64  
img = cv2.imread(img_path)

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title("Input Image")
plt.show()

resize = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))

plt.imshow(resize.numpy().astype(np.uint8))
plt.axis('off')
plt.title("Resized Image")
plt.show()

input_tensor = np.expand_dims(resize / 255.0, axis=0)

if input_tensor.shape[-1] != 1:
    input_tensor = tf.image.rgb_to_grayscale(input_tensor)

pred = model.predict(input_tensor)

print(f"Raw prediction: {pred[0][0]:.4f}")
if pred > 0.5:
    print("Predicted: Not Autistic")
else:
    print("Predicted: Autistic")